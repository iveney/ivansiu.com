<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: algorithm | Zigang Xiao]]></title>
  <link href="http://blog.ivansiu.com/blog/categories/algorithm/atom.xml" rel="self"/>
  <link href="http://blog.ivansiu.com/"/>
  <updated>2013-10-07T18:09:55-05:00</updated>
  <id>http://blog.ivansiu.com/</id>
  <author>
    <name><![CDATA[Zigang Xiao (Ivan)]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Network Flow: Push-relabel algorithm]]></title>
    <link href="http://blog.ivansiu.com/blog/2013/10/07/network-flow-push-relabel-algorithm/"/>
    <updated>2013-10-07T18:08:00-05:00</updated>
    <id>http://blog.ivansiu.com/blog/2013/10/07/network-flow-push-relabel-algorithm</id>
    <content type="html"><![CDATA[<p>According to CLRS: Many of the asymptotically fastest maximum-flow algorithms are push-relabel algorithms, and the fastest actual implementations of maximum-flow algorithms are based on the push-relabel method. Push-relabel methods also efficiently solve other flow problems, such as the minimum-cost flow problem.</p>

<p>This algorithm has a very different flavor. The overall idea is to generate a &lsquo;preflow&rsquo; that may not satisfy the flow properties, and keep &lsquo;pushing&rsquo;) and &lsquo;elevating&rsquo; (relabelling) the vertices until we cannot do that. We then remove the &lsquo;excess&rsquo; from the preflow and obtain a valid flow, which is also a max flow. In particular, the in-flow may be larger than out-flow at a vertex. The amount of overflow is called &lsquo;excess&rsquo;.</p>

<!-- more -->


<p>The intuition behind is this: think of the vertices as platforms that have different height, where initially $S$ has $|V|$ height and all other vertices have 0 heights. The flow can only be pushed from higher vertices to lower vertices. Whenever we do not have any flow to push, we find some vertex  that has unsaturated out edge to its neighbor vertices to &lsquo;relabel&rsquo;, i.e., elevating its height such that we can continue to &lsquo;push&rsquo;. Thus, there are two operations &lsquo;push&rsquo; and &lsquo;relabel&rsquo; (and thus the name):</p>

<pre><code>push: sending excess from u to v
relabel: increase the height of u to min({v: neighbor of u})+1
</code></pre>

<p>The algorithm is as follows:</p>

<pre><code>Initialize s.h = |V|, u.h = 0 for u != s. // u.h is the height of vertex u
For all (s, u), push c(s, u). // saturate all outgoing edges from s.
While there is vertex that can be pushed or relabel
  do push or relabel
End while
return F.
</code></pre>

<p>The naive implementation has runtime $O(|V|^2 |E|)$, and can be improved to $O(|V|^3)$.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Network Flow: Ford-Fulkerson Method]]></title>
    <link href="http://blog.ivansiu.com/blog/2013/10/03/network-flow-ford-fulkerson-method/"/>
    <updated>2013-10-03T18:13:00-05:00</updated>
    <id>http://blog.ivansiu.com/blog/2013/10/03/network-flow-ford-fulkerson-method</id>
    <content type="html"><![CDATA[<p>Basic method (framework) is Ford-Fulkerson. It&rsquo;s called a &ldquo;method&rdquo; because it&rsquo;s
general, there can be different implementation that yield different complexity.
It looks like this:</p>

<pre><code>Let F be an empty flow
While there is augmenting path P from s to t
    Augment F with P
End while
</code></pre>

<p>The problem is how we find the augmenting path efficiently. A naive
implementation is to use DFS to randomly pick a $s-t$ path and augment it.
However, it has two problems:</p>

<!-- more -->


<ol>
<li>The algorithm may not terminate, this happens when the capacity is
irrational number (we can always scale rational to integer). When the
capacity is irrational, the flow may fluctuate and never converge.</li>
<li>Even when the capacity is integer, the algorithm may be too slow. The
runtime depends on the size of flow $|F|$, which means if $|F|$ is large, it
takes a long time to stop. To see this, note that DFS takes $|E|$ time, in the
worst case, $F$ may grow by 1 at each iteration (since capacity is integer).
Thus, the complexity is $O(|E||F|)$.</li>
</ol>


<p>To handle, this, Edmonds-Karp algorithm simply replaces the DFS as BFS, which
finds a shortest each time (use unit length on edges in the residual graph).
The major points are:</p>

<ul>
<li>The length shortest path is guaranteed to monotonically increase at each
iteration. This can be proven by contradiction.</li>
<li>The number of iterations are $O(|V||E|)$.

<ul>
<li>Each augmenting path (shortest path) can saturate one edge, and this edge
will disappear from the residual graph. We call this edge &lsquo;critical&rsquo;.</li>
<li>An edge $(u, v)$ becomes critical to the time when it next becomes
critical, the distance to $u$ from the source increases by at least 2.</li>
<li>Thus, the total number of critical edges during execution is $O(|V||E|)$.</li>
<li>Each augmenting path contains at least one critical edge, thus $O(|V||E|)$.</li>
</ul>
</li>
<li>The running time is thus $O(|V||E|^2)$ since each iteration we run a BFS
which costs $O(|E|)$. This can be improved to $O(|V|^2|E|)$ with more
efficient data structure (Dinic).</li>
</ul>

]]></content>
  </entry>
  
</feed>
