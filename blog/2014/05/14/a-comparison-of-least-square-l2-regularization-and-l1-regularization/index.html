
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>A Comparison of Least Square, L2-regularization and L1-regularization - Zigang Xiao</title>
  <meta name="author" content="Zigang Xiao (Ivan)">
  <link rel="author" href="humans.txt">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">

  
    
  
  <meta name="description" content="Recovered Coefficients by Different Methods Problem Setting
Ordinary Least Square (OLS), L2-regularization and L1-regularization are all techniques &hellip;">
  
  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://blog.ivansiu.com/blog/2014/05/14/a-comparison-of-least-square-l2-regularization-and-l1-regularization/">
  <link href='http://fonts.googleapis.com/css?family=Cantarell' rel='stylesheet' type='text/css'>
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/atom.xml" rel="alternate" title="Zigang Xiao" type="application/atom+xml">
  <meta name="og:type" content="website" />
  <meta name="og:site_name" content="Zigang Xiao" />
  <meta name="og:title" content="A Comparison of Least Square, L2-regularization and L1-regularization" />
  <meta name="og:description" content="Recovered Coefficients by Different Methods Problem Setting
Ordinary Least Square (OLS), L2-regularization and L1-regularization are all techniques &hellip;" />
  <meta name="og:url" content="http://blog.ivansiu.com/blog/2014/05/14/a-comparison-of-least-square-l2-regularization-and-l1-regularization/"/>
  <meta name="url" content="http://blog.ivansiu.com/blog/2014/05/14/a-comparison-of-least-square-l2-regularization-and-l1-regularization/">
  
  <meta name="subject" content="Machine Learning"/>
  <meta name="category" content="Machine Learning"/>
  
  <meta name="distribution" content="global">
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

<!-- MathJax -->
<!-- see:

http://www.idryman.org/blog/2012/03/10/writing-math-equations-on-octopress/ 
http://drz.ac/2013/01/03/blogging-with-math/
http://drz.ac/javascripts/MathJaxLocal.js
http://blog.zhengdong.me/2012/12/19/latex-math-in-octopress
http://docs.mathjax.org/en/latest/configuration.html

-->

<script type="text/javascript"
	src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

<script type="text/javascript" src="/javascripts/MathJaxLocal.js"></script>

<!-- Facebook OpenGraph -->
<meta property="og:image" content="http://blog.ivansiu.com/favicon.png">

<!-- Fav icon 
see: 
https://github.com/imathis/octopress/issues/599
-->


  

  
<link href="/favicon.ico" rel="icon">
</head>

<body   >
  <nav role="navigation"><div class="navbar">
  <div class="navbar-inner">
    <a class="brand" href="/">Zigang Xiao</a>
    <ul class="nav">
      <li><a href="/">Home</a></li>
      <li><a href="/blog/archives">Archives</a></li>
    </ul>
        <ul class="nav">
      <li><a href="/blog/categories">Categories</a></li>
    </ul>

    <ul class="nav" data-subscription="rss">
      <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
      
    </ul>
      
    <form class="navbar-form" action="http://google.com/search" method="get">
      <fieldset role="search">
        <input type="hidden" name="q" value="site:blog.ivansiu.com" />
        <input class="span2" type="text" name="q" results="0" placeholder="Search"/>
      </fieldset>
    </form>
      
  </div>
</div>
</nav>
  <div class="wrapper_single">
    <div class="container">
      <article class="span8 offset2" role="article">
        <div class="article-format">

  <header>
    
      <h1 class="entry-title">A Comparison of Least Square, L2-regularization and L1-regularization</h1>
    
    
      <p class="meta">
        
  


  
    <span class="byline author vcard">by <span class="fn">Zigang Xiao (Ivan)</span></span>
  

 - 
        








  


<time datetime="2014-05-14T21:32:38-05:00" pubdate data-updated="true">May 14<span>th</span>, 2014</time> - 
        

posted in
<span class="categories">
  
    <a class='category' href='/blog/categories/machine-learning/'>Machine Learning</a>
  
</span>


        
      </p>
    
  </header>


  <div class="entry-content"><figure>
<img src="https://dl.dropboxusercontent.com/u/3315210/blog/2014-05-14-a-comparison-of-least-square-l2-regularization-and-l1-regularization/coef.png" alt="Recovered Coefficients by Different Methods" /><figcaption>Recovered Coefficients by Different Methods</figcaption>
</figure>
<h1 id="problem-setting">Problem Setting</h1>
<p>Ordinary Least Square (OLS), L2-regularization and L1-regularization are all techniques of finding solutions in a linear system. However, they serve for different purposes. Recently, L1-regularization gains much attention due to its ability in finding sparse solutions. This post demonstrates this by comparing OLS, L2 and L1 regularization.</p>
<!-- more -->

<p>Consider the following linear system:</p>
<p><span class="math">\[Ax = y\]</span></p>
<p>where <span class="math">\(A \in \reals^{m \times n}\)</span>, <span class="math">\(m\)</span> is the number of rows (observations) and <span class="math">\(n\)</span> is the number of columns (variable dimension), <span class="math">\(x\)</span> is the variable coefficients and <span class="math">\(y\)</span> is the response. There are three cases to consider:</p>
<ol type="1">
<li><span class="math">\(m=n\)</span>. This is the common-seen case. If <span class="math">\(A\)</span> is not degenerate, the solution is unique.</li>
<li><span class="math">\(m&gt;n\)</span>. This is called <em>over-determined linear system</em>. There is usually <em>no</em> solutions, but an <em>approximation</em> can be easily found by minimizing the <em>residue cost</em> <span class="math">\(\norm{Ax-y}^2_2\)</span> using least square methods, and it has a nice closed-form solution <span class="math">\(x_{ls}=(A^T A)^{-1} A^T y\)</span>. In L2-regularization, we add a penalize term to minimize the 2-norm of the coefficients. Thus, the objective becomes: <span class="math">\[\min_x \norm{Ax-y}^2_2 + \alpha \norm{x}_2\]</span> where <span class="math">\(\alpha\)</span> is a weight to decide the importance of the regularization.</li>
<li><span class="math">\(m&lt;n\)</span>. This is called <em>under-determined linear system</em>. There is usually no solution or infinite solutions. This is where it get interesting: when we have some prior knowledge in the solution structure, such as sparsity, we can have a ‘metric’ to find a better solution among a whole bunch. The objective is thus: <span class="math">\[\min_x \norm{Ax-y}^2_2 + \alpha \norm{x}_1\]</span> The optimization technique for the above problem is called <a href="http://www-stat.stanford.edu/~tibs/lasso.html">lasso</a>, and there is an advanced version called <a href="http://en.wikipedia.org/wiki/Elastic_net_regularization">elastic net</a>, which <a href="http://scikit-learn.org/stable/modules/linear_model.html#elastic-net">combines the L2 and L1 regularization together</a>, hoping to get the advantages of both: L1 regularization finds sparse solution but introduces a large Mean Square Error (MSE) error, while L2 is better at minimizing MSE.</li>
</ol>
<h2 id="an-example">An Example</h2>
<p>In the following, we show their performances by solving a simple case.</p>
<div class="bogus-wrapper">
<notextile>
<figure class='code'><figcaption>
<span>regression_ex.m</span>
</figcaption>
<div class="highlight">
<table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
</pre></td><td class='code'><pre><code class='matlab'><span class='line'><span class="c">% Compare Ordinary Least square (no regularization), L2-reguarlized (Ridge),</span>
</span><span class='line'><span class="c">% L1-regualarized (Lasso) regression in finding the sparse coefficient</span>
</span><span class='line'><span class="c">% in a underdetermined linear system</span>
</span><span class='line'>
</span><span class='line'><span class="n">rng</span><span class="p">(</span>0<span class="p">);</span>  <span class="c">% for reproducibility</span>
</span><span class='line'><span class="n">m</span> <span class="p">=</span> 50<span class="p">;</span>  <span class="c">% num samples</span>
</span><span class='line'><span class="n">n</span> <span class="p">=</span> 200<span class="p">;</span> <span class="c">% num variables, note that n &gt; m</span>
</span><span class='line'>
</span><span class='line'><span class="n">A</span> <span class="p">=</span> <span class="nb">rand</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">n</span><span class="p">);</span>
</span><span class='line'><span class="n">x</span> <span class="p">=</span> <span class="nb">zeros</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> 1<span class="p">);</span>
</span><span class='line'><span class="n">nz</span> <span class="p">=</span> 10<span class="p">;</span> <span class="c">% 10 non-zeros variables (sparse)</span>
</span><span class='line'><span class="n">nz_idx</span> <span class="p">=</span> <span class="n">randperm</span><span class="p">(</span><span class="n">n</span><span class="p">);</span>
</span><span class='line'><span class="n">x</span><span class="p">(</span><span class="n">nz_idx</span><span class="p">(</span>1<span class="p">:</span><span class="n">nz</span><span class="p">))</span> <span class="p">=</span> 3 <span class="o">*</span> <span class="nb">rand</span><span class="p">(</span><span class="n">nz</span><span class="p">,</span> 1<span class="p">);</span>
</span><span class='line'><span class="n">y</span> <span class="p">=</span> <span class="n">A</span><span class="o">*</span><span class="n">x</span><span class="p">;</span>
</span><span class='line'><span class="n">y</span> <span class="p">=</span> <span class="n">y</span> <span class="o">+</span> 0<span class="p">.</span>05 <span class="o">*</span> <span class="nb">rand</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> 1<span class="p">);</span> <span class="c">% add some noise</span>
</span><span class='line'>
</span><span class='line'><span class="c">% plot original x</span>
</span><span class='line'><span class="n">subplot</span><span class="p">(</span>2<span class="p">,</span> 2<span class="p">,</span> 1<span class="p">);</span>
</span><span class='line'><span class="n">bar</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">axis</span> <span class="n">tight</span><span class="p">;</span>
</span><span class='line'><span class="n">title</span><span class="p">(</span><span class="s">&#39;Original coefficients&#39;</span><span class="p">);</span>
</span><span class='line'>
</span><span class='line'><span class="c">% OLS</span>
</span><span class='line'><span class="n">x_ols</span> <span class="p">=</span> <span class="n">A</span> <span class="o">\</span> <span class="n">y</span><span class="p">;</span>
</span><span class='line'><span class="n">subplot</span><span class="p">(</span>2<span class="p">,</span> 2<span class="p">,</span> 2<span class="p">);</span>
</span><span class='line'><span class="n">bar</span><span class="p">(</span><span class="n">x_ols</span><span class="p">),</span> <span class="n">axis</span> <span class="n">tight</span><span class="p">;</span>
</span><span class='line'><span class="n">title</span><span class="p">(</span><span class="s">&#39;Ordinary Least Square&#39;</span><span class="p">);</span>
</span><span class='line'><span class="n">y_ols</span> <span class="p">=</span> <span class="n">A</span> <span class="o">*</span> <span class="n">x_ols</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'><span class="c">% L2 (Ridge) </span>
</span><span class='line'><span class="n">x_l2</span> <span class="p">=</span> <span class="n">ridge</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> 1<span class="n">e</span><span class="o">-</span>5<span class="p">,</span> 0<span class="p">);</span>  <span class="c">% last parameter = 00 to generate intercept term</span>
</span><span class='line'><span class="n">b_l2</span> <span class="p">=</span> <span class="n">x_l2</span><span class="p">(</span>1<span class="p">);</span>
</span><span class='line'><span class="n">x_l2</span> <span class="p">=</span> <span class="n">x_l2</span><span class="p">(</span>2<span class="p">:</span><span class="k">end</span><span class="p">);</span>
</span><span class='line'><span class="n">subplot</span><span class="p">(</span>2<span class="p">,</span> 2<span class="p">,</span> 3<span class="p">);</span>
</span><span class='line'><span class="n">bar</span><span class="p">(</span><span class="n">x_l2</span><span class="p">),</span> <span class="n">axis</span> <span class="n">tight</span><span class="p">;</span>
</span><span class='line'><span class="n">title</span><span class="p">(</span><span class="s">&#39;L2 Regularization&#39;</span><span class="p">);</span>
</span><span class='line'><span class="n">y_l2</span> <span class="p">=</span> <span class="n">A</span> <span class="o">*</span> <span class="n">x_l2</span> <span class="o">+</span> <span class="n">b_l2</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'><span class="c">% L1 (Lasso)</span>
</span><span class='line'><span class="p">[</span><span class="n">x_l1</span><span class="p">,</span> <span class="n">fitinfo</span><span class="p">]</span> <span class="p">=</span> <span class="n">lasso</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="s">&#39;Lambda&#39;</span><span class="p">,</span> 0<span class="p">.</span>1<span class="p">);</span>
</span><span class='line'><span class="n">b_l1</span> <span class="p">=</span> <span class="n">fitinfo</span><span class="p">.</span><span class="n">Intercept</span><span class="p">(</span>1<span class="p">);</span>
</span><span class='line'><span class="n">y_l1</span> <span class="p">=</span> <span class="n">A</span> <span class="o">*</span> <span class="n">x_l1</span> <span class="o">+</span> <span class="n">b_l1</span><span class="p">;</span>
</span><span class='line'><span class="n">subplot</span><span class="p">(</span>2<span class="p">,</span> 2<span class="p">,</span> 4<span class="p">);</span>
</span><span class='line'><span class="n">bar</span><span class="p">(</span><span class="n">x_l1</span><span class="p">),</span> <span class="n">axis</span> <span class="n">tight</span><span class="p">;</span>
</span><span class='line'><span class="n">title</span><span class="p">(</span><span class="s">&#39;L1 Regularization&#39;</span><span class="p">);</span>
</span><span class='line'>
</span><span class='line'><span class="c">% L1 (Elastic Net)</span>
</span><span class='line'><span class="p">[</span><span class="n">x_en</span><span class="p">,</span> <span class="n">fitinfo_en</span><span class="p">]</span> <span class="p">=</span> <span class="n">lasso</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="s">&#39;Lambda&#39;</span><span class="p">,</span> 0<span class="p">.</span>1<span class="p">,</span> <span class="s">&#39;Alpha&#39;</span><span class="p">,</span> 0<span class="p">.</span>7<span class="p">);</span>
</span><span class='line'><span class="n">b_en</span> <span class="p">=</span> <span class="n">fitinfo_en</span><span class="p">.</span><span class="n">Intercept</span><span class="p">(</span>1<span class="p">);</span>
</span><span class='line'><span class="n">y_en</span> <span class="p">=</span> <span class="n">A</span> <span class="o">*</span> <span class="n">x_en</span> <span class="o">+</span> <span class="n">b_en</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'><span class="n">MSE_y</span> <span class="p">=</span> <span class="p">[</span><span class="n">mse</span><span class="p">(</span><span class="n">y_ols</span><span class="o">-</span><span class="n">y</span><span class="p">),</span> <span class="n">mse</span><span class="p">(</span><span class="n">y_l2</span><span class="o">-</span><span class="n">y</span><span class="p">),</span> <span class="n">mse</span><span class="p">(</span><span class="n">y_l1</span><span class="o">-</span><span class="n">y</span><span class="p">),</span> <span class="n">mse</span><span class="p">(</span><span class="n">y_en</span><span class="o">-</span><span class="n">y</span><span class="p">)];</span>
</span><span class='line'><span class="nb">disp</span><span class="p">(</span><span class="s">&#39;Mean square error: &#39;</span><span class="p">)</span>
</span><span class='line'><span class="n">fprintf</span><span class="p">(</span><span class="s">&#39;%g    &#39;</span><span class="p">,</span> <span class="n">MSE_y</span><span class="p">);</span> <span class="n">fprintf</span><span class="p">(</span><span class="s">&#39;\n\n&#39;</span><span class="p">);</span>
</span><span class='line'>
</span><span class='line'><span class="c">% Plot the recovered coefficients</span>
</span><span class='line'><span class="n">figure</span><span class="p">,</span> <span class="n">hold</span> <span class="n">on</span>
</span><span class='line'><span class="n">plot</span><span class="p">(</span><span class="n">x_l1</span><span class="p">,</span> <span class="s">&#39;b&#39;</span><span class="p">);</span>
</span><span class='line'><span class="n">plot</span><span class="p">(</span><span class="n">x_en</span><span class="p">,</span> <span class="s">&#39;r&#39;</span><span class="p">);</span>
</span><span class='line'><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="s">&#39;g--&#39;</span><span class="p">);</span>
</span><span class='line'><span class="n">legend</span><span class="p">(</span><span class="s">&#39;Lasso Coef&#39;</span><span class="p">,</span> <span class="s">&#39;Elastic Net coef&#39;</span><span class="p">,</span> <span class="s">&#39;Original Coef&#39;</span><span class="p">);</span>
</span></code></pre></td></tr></table>
</div>
</figure>
</notextile>
</div>
<p>Output:</p>
<div class="bogus-wrapper">
<notextile>
<figure class='code'><figcaption>
<span></span>
</figcaption>
<div class="highlight">
<table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='matlab'><span class='line'><span class="n">Mean</span> <span class="n">square</span> <span class="n">error</span><span class="p">:</span>
</span><span class='line'>1<span class="p">.</span>81793<span class="n">e</span><span class="o">-</span>29    7<span class="p">.</span>93494<span class="n">e</span><span class="o">-</span>15    0<span class="p">.</span>0975002    0<span class="p">.</span>0641214
</span></code></pre></td></tr></table>
</div>
</figure>
</notextile>
</div>
<p>The above code snippets generates an under-determined matrix <span class="math">\(A\)</span>, and a sparse coefficients which has 200 variables but only 10 of them are non-zeros. Noises are added to the responses. We then run the proposed three methods to try to recover the coefficients. It then generates two plots:</p>
<ol type="1">
<li>The first plot is as shown in the top. As we can see, OLS does a very bad job, though the MSE is minimized to zero. L2-regularization do find some of the sparks, but there are also lots of non-zeros introduced. Finally, L1-regularization finds most of the non-zeros correctly and resembles the original coefficients most.</li>
<li>The second plot shows how similar the recovered coefficients by lasso and elastic nets resemble the original coefficients. As we can see, both of them can recover most parts, while elastic nets contain some small ‘noise’. However, elastic net yields a slightly better MSE than lasso.</li>
</ol>
<figure>
<img src="https://dl.dropboxusercontent.com/u/3315210/blog/2014-05-14-a-comparison-of-least-square-l2-regularization-and-l1-regularization/plot.png" alt="Plot of Coefficients" /><figcaption>Plot of Coefficients</figcaption>
</figure>
<h2 id="probing-further">Probing Further</h2>
<p>Scikit has some excellent examples on regualarization (<a href="http://scikit-learn.org/stable/modules/linear_model.html">1</a>, <a href="http://scikit-learn.org/stable/auto_examples/linear_model/plot_lasso_and_elasticnet.html">2</a>). Quora has an excellent <a href="http://www.quora.com/Machine-Learning/What-is-the-difference-between-L1-and-L2-regularization">discussion</a> on L2 vs L1 regualarization. I found the top three answers very useful in understanding deeper, especially from the <em>Bayesian regularization paradigm</em> perspective by thinking the regularization as MAP (Maximum A Posteriori) that adds a Laplacian (L1) or Gaussian (L2) prior to the original objective.</p>
<div class="references">

</div>
</div>


  <footer>
    <p class="meta">
      
  


  
    <span class="byline author vcard">by <span class="fn">Zigang Xiao (Ivan)</span></span>
  

 - 
      








  


<time datetime="2014-05-14T21:32:38-05:00" pubdate data-updated="true">May 14<span>th</span>, 2014</time> - 
      

posted in
<span class="categories">
  
    <a class='category' href='/blog/categories/machine-learning/'>Machine Learning</a>
  
</span>


    </p>
    
      <div class="sharing">
  
  <a href="//twitter.com/share" class="twitter-share-button" data-url="http://blog.ivansiu.com/blog/2014/05/14/a-comparison-of-least-square-l2-regularization-and-l1-regularization/" data-via="iveney" data-counturl="http://blog.ivansiu.com/blog/2014/05/14/a-comparison-of-least-square-l2-regularization-and-l1-regularization/" >Tweet</a>
  
  
  
    <div class="fb-like" data-layout="button_count" data-send="true" data-width="450" data-show-faces="false" style="vertical-align: top;"></div>
  
</div>

    
    
      <a class="pull-left" href="/blog/2014/05/02/debugging-applescript-print-to-a-file/" title="Previous Post: Debugging AppleScript: print to a file">&laquo; Debugging AppleScript: print to a file</a>
    
    
      <a class="pull-right" href="/blog/2014/05/18/sparse-signal-reconstruction-via-l1-minimization/" title="Next Post: Sparse Signal Reconstruction via L1-minimization">Sparse Signal Reconstruction via L1-minimization &raquo;</a>
    
  </footer>

</div>

        
          <div class="article-format">
            <h1>Comments</h1>
            <div id="disqus_thread" aria-live="polite"><noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>
          </div>
        
      </article>
    </div>
  </div>
  <div id="footer-widgets">
  <div class="container">
    <div class="row">
<!--
  <div class="span3">
    <h2>recent posts</h2>
    <ul class="recent_posts">
      
        <li>
          <a href="/blog/2014/05/19/sparse-image-reconstruction-via-l1-minimization/">Sparse Gradient Image Reconstruction via L1-minimization</a>
        </li>
      
        <li>
          <a href="/blog/2014/05/18/sparse-signal-reconstruction-via-l1-minimization/">Sparse Signal Reconstruction via L1-minimization</a>
        </li>
      
        <li>
          <a href="/blog/2014/05/14/a-comparison-of-least-square-l2-regularization-and-l1-regularization/">A Comparison of Least Square, L2-regularization and L1-regularization</a>
        </li>
      
        <li>
          <a href="/blog/2014/05/02/debugging-applescript-print-to-a-file/">Debugging AppleScript: print to a file</a>
        </li>
      
        <li>
          <a href="/blog/2014/05/01/os-x-reveal-file-in-console/">OS X: reveal file in console</a>
        </li>
      
    </ul>
    <h2><a href="/blog/archives">archives</a></h2>
  </div>
  <div class="span3">
    

  </div>
  <div class="span4">
    <h2>twitter</h2>
<a class="twitter-timeline" href="https://twitter.com/iveney" data-widget-id="390943167203127296">Tweets by @iveney</a>
<script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+"://platform.twitter.com/widgets.js";fjs.parentNode.insertBefore(js,fjs);}}(document,"script","twitter-wjs");</script>

  </div>
  <div class="span2">
    <h2>found on</h2>

<a href="https://github.com/iveney/" rel="tooltip" title="Github"><img class="social_icon" title="Github" alt="github icon" src="/images/glyphicons_381_github.png"></a>



<a href="http://stackoverflow.com/users/577704/" rel="tooltip" title="Stack Overflow"><img class="social_icon" title="Stack Overflow" alt="stack overflow icon" src="/images/glyphicons_400_stack_overflow.png"></a>



<a href="http://www.linkedin.com/in/zgxiao" rel="tooltip" title="Linkedin"><img class="social_icon" title="Linkedin" alt="Linkedin icon" src="/images/glyphicons_377_linked_in.png"></a>



<a href="http://twitter.com/iveney" rel="tooltip" title="Twitter"><img class="social_icon" title="Twitter" alt="Twitter icon" src="/images/glyphicons_391_twitter_t.png"></a>









<a href="https://ews.illinois.edu/~zxiao2" rel="tooltip" title="Professional"><img class="social_icon" title="Professional" alt="Professional icon" src="/images/glyphicons_003_user.png"></a>


  </div>
-->
</div>

  </div>
</div>
<footer class="footer">
  <div class="container">
    <p class="pull-left">
  <a href="/">Zigang Xiao</a>
  - Copyright &copy; 2014 - Zigang Xiao (Ivan)
</p>
<p class="pull-right">
  <span>Powered by <a href="http://octopress.org/">Octopress</a>.</span>
  
    <span>Designed by <a href="http://www.AdrianArtiles.com">Adrian Artiles</a>.</span>
  
</p>

  </div>
</footer>

  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.7.2/jquery.min.js" type="text/javascript"></script>
<script>window.jQuery || document.write('<script src="/javascripts/libs/jquery-1.7.2.min.js" type="text/javascript"><\/script>')</script>
<script src="/javascripts/libs/bootstrap.min.js" type="text/javascript"></script>
<script src="/javascripts/jquery.tweet.js" type="text/javascript"></script>
<script src="/javascripts/jquery.instagram.js" type="text/javascript"></script>
<script src="/javascripts/libs/jquery.masonry.min.js" type="text/javascript"></script>
<script src="/javascripts/custom.js" type="text/javascript"></script>


<script type="text/javascript">
      var disqus_shortname = 'iveney';
      
        
        // var disqus_developer = 1;
        var disqus_identifier = 'http://blog.ivansiu.com/blog/2014/05/14/a-comparison-of-least-square-l2-regularization-and-l1-regularization/';
        var disqus_url = 'http://blog.ivansiu.com/blog/2014/05/14/a-comparison-of-least-square-l2-regularization-and-l1-regularization/';
        var disqus_script = 'embed.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = 'http://' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>



<div id="fb-root"></div>
<script>(function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0];
  if (d.getElementById(id)) {return;}
  js = d.createElement(s); js.id = id;
  js.src = "//connect.facebook.net/en_US/all.js#appId=212934732101925&xfbml=1";
  fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));</script>





  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = 'http://platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>




</body>
</html>
